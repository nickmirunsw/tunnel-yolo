{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/.* /content/* || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "# --- Install and Setup ---\n",
        "!pip install -q ultralytics\n",
        "\n",
        "# Unzip dataset to two locations: 'dataset' and 'custom_data'\n",
        "!unzip -q /content/data-4.zip -d /content/dataset\n",
        "!unzip -q /content/data-4.zip -d /content/custom_data\n",
        "\n",
        "# Check contents\n",
        "!ls /content/dataset\n",
        "\n",
        "# Download helper script for train-validation split\n",
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# Run the split script (90% training, 10% validation)\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.9\n",
        "\n",
        "# --- Generate data.yaml dynamically ---\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "    \"\"\"Creates a data.yaml config file from classes.txt\"\"\"\n",
        "    if not os.path.exists(path_to_classes_txt):\n",
        "        print(f'classes.txt file not found! Please create one at {path_to_classes_txt}')\n",
        "        return\n",
        "\n",
        "    with open(path_to_classes_txt, 'r') as f:\n",
        "        classes = [line.strip() for line in f if line.strip()]\n",
        "    number_of_classes = len(classes)\n",
        "\n",
        "    data = {\n",
        "        'path': '/content/data',\n",
        "        'train': 'train/images',\n",
        "        'val': 'validation/images',\n",
        "        'nc': number_of_classes,\n",
        "        'names': classes\n",
        "    }\n",
        "\n",
        "    with open(path_to_data_yaml, 'w') as f:\n",
        "        yaml.dump(data, f, sort_keys=False)\n",
        "\n",
        "    print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "# Define paths and run the config generator\n",
        "path_to_classes_txt = '/content/custom_data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "# Show contents of the generated YAML\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml\n",
        "\n",
        "# --- Train YOLOv11s Model ---\n",
        "!yolo detect train data=/content/data.yaml model=yolo11s.pt epochs=60 imgsz=640\n",
        "\n",
        "# --- Run Predictions on Validation Set and Save Outputs ---\n",
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True\n",
        "\n",
        "# --- Preview Some Prediction Outputs ---\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob('/content/runs/detect/predict/*.jpg')[:10]:\n",
        "    display(Image(filename=image_path, height=400))\n",
        "    print('\\n')\n",
        "\n",
        "# --- Load Trained Model and Print Class Names ---\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('runs/detect/train/weights/best.pt')\n",
        "print(model.names)\n",
        "\n",
        "# --- Filter and Save Only Images with 'crown' Detections ---\n",
        "from PIL import Image as PILImage, ImageDraw\n",
        "import os\n",
        "\n",
        "results = model.predict(source='data/validation/images', save=False)\n",
        "os.makedirs('filtered_outputs', exist_ok=True)\n",
        "\n",
        "for result in results:\n",
        "    img_path = result.path\n",
        "    img = PILImage.open(img_path).convert('RGB')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    boxes = result.boxes.xyxy.cpu()\n",
        "    classes = result.boxes.cls.cpu().numpy()\n",
        "    scores = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "    for box, cls_id, score in zip(boxes, classes, scores):\n",
        "        if model.names[int(cls_id)] == 'crown':\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            label = f\"crown {score:.2f}\"\n",
        "            draw.rectangle([x1, y1, x2, y2], outline='blue', width=3)\n",
        "            draw.text((x1, y1 - 10), label, fill='blue')\n",
        "\n",
        "    output_path = os.path.join('filtered_outputs', os.path.basename(img_path))\n",
        "    img.save(output_path)\n",
        "\n",
        "# --- Display Filtered Outputs ---\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob('filtered_outputs/*.png'):\n",
        "    display(Image(filename=image_path, height=400))\n",
        "    print('\\n')\n",
        "\n",
        "# # --- Optional: Run Prediction on a Specific Image ---\n",
        "# results = model.predict(source='/content/test.jpeg', save=False)\n",
        "\n",
        "# for result in results:\n",
        "#     img = PILImage.open(result.path).convert(\"RGB\")\n",
        "#     draw = ImageDraw.Draw(img)\n",
        "\n",
        "#     for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n",
        "#         label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
        "#         x1, y1, x2, y2 = map(int, box)\n",
        "#         draw.rectangle([x1, y1, x2, y2], outline=\"black\", width=2)\n",
        "#         draw.text((x1, y1 - 10), label, fill=\"red\")\n",
        "\n",
        "#     display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(\"1.png\")\n",
        "\n",
        "# Resize for better OCR (optional)\n",
        "scale_percent = 200  # scale up for better OCR accuracy\n",
        "width = int(image.shape[1] * scale_percent / 100)\n",
        "height = int(image.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "resized = cv2.resize(image, dim, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# Convert to grayscale for OCR\n",
        "gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Use pytesseract to extract all displacement text\n",
        "custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
        "text = pytesseract.image_to_string(gray, config=custom_config)\n",
        "\n",
        "# Clean and parse numeric values\n",
        "lines = text.splitlines()\n",
        "displacements = []\n",
        "for line in lines:\n",
        "    try:\n",
        "        val = float(line.strip())\n",
        "        displacements.append(val)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# Identify color band area (hardcoded cropping based on image)\n",
        "# Adjust these if your layout changes\n",
        "color_bar_area = resized[50:-50, 20:60]  # Crop to focus only on color bar\n",
        "num_bands = len(displacements)\n",
        "\n",
        "# Calculate height per band\n",
        "band_height = color_bar_area.shape[0] // num_bands\n",
        "\n",
        "# Extract RGB for each band\n",
        "color_values = []\n",
        "for i in range(num_bands):\n",
        "    y_start = i * band_height\n",
        "    y_end = (i + 1) * band_height\n",
        "    band = color_bar_area[y_start:y_end, :]\n",
        "\n",
        "    # Compute average color (mean RGB)\n",
        "    mean_color = cv2.mean(band)[:3]  # drop alpha\n",
        "    mean_color = tuple(int(c) for c in mean_color)\n",
        "    color_values.append(mean_color)\n",
        "\n",
        "# Combine results\n",
        "# Remove first and last entries (extra info like min/max text)\n",
        "displacements = displacements[1:-1]\n",
        "color_values = color_values[1:-1]\n",
        "\n",
        "# Combine results\n",
        "data = []\n",
        "for disp, (r, g, b) in zip(displacements, color_values):\n",
        "    data.append({\"Displacement\": disp, \"R\": r, \"G\": g, \"B\": b})\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"legend_rgb_values.csv\", index=False)\n",
        "\n",
        "print(\"âœ… CSV saved as 'legend_rgb_values.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load image\n",
        "img = cv2.imread(\"2.png\")\n",
        "\n",
        "# Convert to LAB color space (better separation of luminance & color)\n",
        "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "# Edge detection to remove thin lines\n",
        "edges = cv2.Canny(img, threshold1=50, threshold2=150)\n",
        "\n",
        "# Dilate to emphasize lines\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "dilated = cv2.dilate(edges, kernel, iterations=1)\n",
        "\n",
        "# Invert to get mask for \"non-line\" (background) areas\n",
        "mask = cv2.bitwise_not(dilated)\n",
        "\n",
        "# Use the mask to get only the background pixels\n",
        "bg_pixels = img[mask == 255]\n",
        "\n",
        "# Compute average background RGB\n",
        "avg_color = np.mean(bg_pixels, axis=0)\n",
        "avg_color = tuple(int(c) for c in avg_color)\n",
        "print(\"Estimated background RGB:\", avg_color)\n",
        "\n",
        "# Load legend RGB table\n",
        "df = pd.read_csv(\"legend_rgb_values.csv\")\n",
        "\n",
        "# Compute Euclidean distance to each RGB entry\n",
        "def color_distance(c1, c2):\n",
        "    return np.sqrt(sum((a - b) ** 2 for a, b in zip(c1, c2)))\n",
        "\n",
        "df[\"Distance\"] = df.apply(lambda row: color_distance(avg_color, (row[\"R\"], row[\"G\"], row[\"B\"])), axis=1)\n",
        "\n",
        "# Get closest match\n",
        "closest_row = df.loc[df[\"Distance\"].idxmin()]\n",
        "closest_disp = closest_row[\"Displacement\"]\n",
        "print(f\"Closest Displacement: {closest_disp:.3f} m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
